{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a63cfd97",
   "metadata": {},
   "source": [
    "# Setup & Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fc80c6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2578d935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\ghosh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Setup complete!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments\n",
    "from peft import LoraConfig, prepare_model_for_kbit_training, get_peft_model\n",
    "from trl import SFTTrainer\n",
    "import torch\n",
    "\n",
    "# Set paths\n",
    "PROJECT_DIR = r\"C:\\Users\\ghosh\\Desktop\\Predictive-Transaction-intelligence-for-bfsi\"\n",
    "DATASET_PATH = os.path.join(PROJECT_DIR, \"Dataset\", \"Fraud.csv\")  # Your fraud dataset\n",
    "OUTPUT_DIR = os.path.join(PROJECT_DIR, \"models\", \"phi3-fraud-detector\")\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b54e933",
   "metadata": {},
   "source": [
    "# Load & Explore Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1428ae7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (6362620, 11)\n",
      "Columns: ['step', 'type', 'amount', 'nameOrig', 'oldbalanceOrg', 'newbalanceOrig', 'nameDest', 'oldbalanceDest', 'newbalanceDest', 'isFraud', 'isFlaggedFraud']\n",
      "No fraud_flag!\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "step",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "amount",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "nameOrig",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "oldbalanceOrg",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "newbalanceOrig",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "nameDest",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "oldbalanceDest",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "newbalanceDest",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "isFraud",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "isFlaggedFraud",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "a6c5cc9b-2ecb-413b-8aa2-f8ac8bf42660",
       "rows": [
        [
         "0",
         "1",
         "PAYMENT",
         "9839.64",
         "C1231006815",
         "170136.0",
         "160296.36",
         "M1979787155",
         "0.0",
         "0.0",
         "0",
         "0"
        ],
        [
         "1",
         "1",
         "PAYMENT",
         "1864.28",
         "C1666544295",
         "21249.0",
         "19384.72",
         "M2044282225",
         "0.0",
         "0.0",
         "0",
         "0"
        ],
        [
         "2",
         "1",
         "TRANSFER",
         "181.0",
         "C1305486145",
         "181.0",
         "0.0",
         "C553264065",
         "0.0",
         "0.0",
         "1",
         "0"
        ],
        [
         "3",
         "1",
         "CASH_OUT",
         "181.0",
         "C840083671",
         "181.0",
         "0.0",
         "C38997010",
         "21182.0",
         "0.0",
         "1",
         "0"
        ],
        [
         "4",
         "1",
         "PAYMENT",
         "11668.14",
         "C2048537720",
         "41554.0",
         "29885.86",
         "M1230701703",
         "0.0",
         "0.0",
         "0",
         "0"
        ]
       ],
       "shape": {
        "columns": 11,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>type</th>\n",
       "      <th>amount</th>\n",
       "      <th>nameOrig</th>\n",
       "      <th>oldbalanceOrg</th>\n",
       "      <th>newbalanceOrig</th>\n",
       "      <th>nameDest</th>\n",
       "      <th>oldbalanceDest</th>\n",
       "      <th>newbalanceDest</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>isFlaggedFraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>9839.64</td>\n",
       "      <td>C1231006815</td>\n",
       "      <td>170136.0</td>\n",
       "      <td>160296.36</td>\n",
       "      <td>M1979787155</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>1864.28</td>\n",
       "      <td>C1666544295</td>\n",
       "      <td>21249.0</td>\n",
       "      <td>19384.72</td>\n",
       "      <td>M2044282225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>TRANSFER</td>\n",
       "      <td>181.00</td>\n",
       "      <td>C1305486145</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>C553264065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>CASH_OUT</td>\n",
       "      <td>181.00</td>\n",
       "      <td>C840083671</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>C38997010</td>\n",
       "      <td>21182.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>11668.14</td>\n",
       "      <td>C2048537720</td>\n",
       "      <td>41554.0</td>\n",
       "      <td>29885.86</td>\n",
       "      <td>M1230701703</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   step      type    amount     nameOrig  oldbalanceOrg  newbalanceOrig  \\\n",
       "0     1   PAYMENT   9839.64  C1231006815       170136.0       160296.36   \n",
       "1     1   PAYMENT   1864.28  C1666544295        21249.0        19384.72   \n",
       "2     1  TRANSFER    181.00  C1305486145          181.0            0.00   \n",
       "3     1  CASH_OUT    181.00   C840083671          181.0            0.00   \n",
       "4     1   PAYMENT  11668.14  C2048537720        41554.0        29885.86   \n",
       "\n",
       "      nameDest  oldbalanceDest  newbalanceDest  isFraud  isFlaggedFraud  \n",
       "0  M1979787155             0.0             0.0        0               0  \n",
       "1  M2044282225             0.0             0.0        0               0  \n",
       "2   C553264065             0.0             0.0        1               0  \n",
       "3    C38997010         21182.0             0.0        1               0  \n",
       "4  M1230701703             0.0             0.0        0               0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(DATASET_PATH)\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "print(f\"Fraud rate: {df['fraud_flag'].mean():.4f}\" if 'fraud_flag' in df.columns else \"No fraud_flag!\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec66286",
   "metadata": {},
   "source": [
    "# Preprocess → JSONL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f610d838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 6,362,620 rows, 11 columns\n",
      "Columns: ['step', 'type', 'amount', 'nameOrig', 'oldbalanceOrg', 'newbalanceOrig', 'nameDest', 'oldbalanceDest', 'newbalanceDest', 'isFraud', 'isFlaggedFraud']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing JSONL: 100%|██████████| 15000/15000 [00:02<00:00, 6911.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved 15,000 examples → C:\\Users\\ghosh\\Desktop\\Predictive-Transaction-intelligence-for-bfsi\\Dataset\\fraud_train.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Paths\n",
    "PROJECT_DIR = r\"C:\\Users\\ghosh\\Desktop\\Predictive-Transaction-intelligence-for-bfsi\"\n",
    "DATASET_PATH = os.path.join(PROJECT_DIR, \"Dataset\", \"Fraud.csv\")\n",
    "JSONL_PATH   = os.path.join(PROJECT_DIR, \"Dataset\", \"fraud_train.jsonl\")\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 1. Load data\n",
    "df = pd.read_csv(DATASET_PATH)\n",
    "print(f\"Loaded {df.shape[0]:,} rows, {df.shape[1]} columns\")\n",
    "print(\"Columns:\", df.columns.tolist())\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 2. Map PaySim columns → the fields we need in the prompt\n",
    "#    - isFraud          → label\n",
    "#    - type             → transaction type (CASH-OUT, TRANSFER, etc.)\n",
    "#    - amount           → amount\n",
    "#    - nameOrig         → sender (use as \"user\")\n",
    "#    - nameDest         → receiver (use as \"merchant\")\n",
    "#    - step             → hour of the day (step % 24)\n",
    "#    - oldbalanceOrg    → sender balance before\n",
    "#    - newbalanceOrig   → sender balance after\n",
    "#    - oldbalanceDest   → receiver balance before\n",
    "#    - newbalanceDest   → receiver balance after\n",
    "#    - isFlaggedFraud   → not used for training\n",
    "\n",
    "# Add derived fields\n",
    "df[\"user_id\"]   = df[\"nameOrig\"]\n",
    "df[\"merchant\"]  = df[\"nameDest\"]\n",
    "df[\"category\"]  = df[\"type\"]\n",
    "df[\"time\"]      = (df[\"step\"] % 24).astype(str) + \":00\"   # hour only\n",
    "df[\"fraud_flag\"]= df[\"isFraud\"]\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 3. Balanced sampling (7 500 fraud + 7 500 safe)\n",
    "fraud = df[df[\"isFraud\"] == 1].sample(7_500, random_state=42)\n",
    "safe  = df[df[\"isFraud\"] == 0].sample(7_500, random_state=42)\n",
    "df_sample = pd.concat([fraud, safe]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 4. Compute average spend **per sender** (user_id)\n",
    "user_avg = df_sample.groupby(\"user_id\")[\"amount\"].mean().to_dict()\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 5. Helper: clean time string\n",
    "def clean_time(t):\n",
    "    return \"unknown\" if pd.isna(t) else str(t)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 6. Build instruction-style example\n",
    "def make_example(row):\n",
    "    avg = user_avg.get(row[\"user_id\"], 100.0)\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": (\n",
    "                    \"You are a transaction safety expert. Classify the transaction as FRAUD or SAFE \"\n",
    "                    \"and explain using amount, time, type, sender/receiver balances, and average user spend.\"\n",
    "                )\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": (\n",
    "                    f\"Sender: {row['user_id'][:10]}… (balance before: ${row['oldbalanceOrg']:.2f}, \"\n",
    "                    f\"after: ${row['newbalanceOrig']:.2f}). \"\n",
    "                    f\"Avg spend: ${avg:.2f}. \"\n",
    "                    f\"Transaction: ${row['amount']:.2f} of type {row['type']} to {row['merchant'][:10]}… \"\n",
    "                    f\"at {clean_time(row['time'])}. Fraud?\"\n",
    "                )\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": (\n",
    "                    f\"{'FRAUD' if row['isFraud'] else 'SAFE'}. \"\n",
    "                    f\"Amount: ${row['amount']:.2f}, Type: {row['type']}, \"\n",
    "                    f\"Time: {clean_time(row['time'])}, \"\n",
    "                    f\"Sender balance change: ${row['oldbalanceOrg']-row['newbalanceOrig']:.2f}, \"\n",
    "                    f\"Avg spend: ${avg:.2f}\"\n",
    "                )\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 7. Write JSONL\n",
    "os.makedirs(os.path.dirname(JSONL_PATH), exist_ok=True)\n",
    "with open(JSONL_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    for _, row in tqdm(df_sample.iterrows(), total=len(df_sample), desc=\"Writing JSONL\"):\n",
    "        f.write(json.dumps(make_example(row)) + \"\\n\")\n",
    "\n",
    "print(f\"\\nSaved {len(df_sample):,} examples → {JSONL_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d0ae36",
   "metadata": {},
   "source": [
    "# Load Model & Tokenizer (4-bit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c285a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
      "Current `flash-attention` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad2cb9b8d07b421eaa230265975e92aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded in 4-bit!\n"
     ]
    }
   ],
   "source": [
    "model_name = \"microsoft/Phi-3.5-mini-instruct\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16,\n",
    "    quantization_config={\n",
    "        \"load_in_4bit\": True,\n",
    "        \"bnb_4bit_compute_dtype\": torch.float16,\n",
    "        \"bnb_4bit_use_double_quant\": True,\n",
    "        \"bnb_4bit_quant_type\": \"nf4\"\n",
    "    },\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "print(\"Model loaded in 4-bit!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50037aac",
   "metadata": {},
   "source": [
    "# Setup LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fba70f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,572,864 || all params: 3,822,652,416 || trainable%: 0.0411\n"
     ]
    }
   ],
   "source": [
    "peft_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d416fd07",
   "metadata": {},
   "source": [
    "# Load Dataset & Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abb6da0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 13500\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 1500\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "jsonl_path= os.path.join(PROJECT_DIR, \"Dataset\", \"fraud_train.jsonl\")\n",
    "dataset = Dataset.from_json(jsonl_path)\n",
    "\n",
    "def format_chat(example):\n",
    "    return {\"text\": tokenizer.apply_chat_template(example[\"messages\"], tokenize=False)}\n",
    "\n",
    "dataset = dataset.map(format_chat, remove_columns=dataset.column_names)\n",
    "dataset = dataset.train_test_split(test_size=0.1)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8631cf85",
   "metadata": {},
   "source": [
    "# Training Arguments & Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b302b4c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ghosh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': dataset_text_field, max_seq_length. Will not be supported from version '1.0.0'.\n",
      "\n",
      "Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "c:\\Users\\ghosh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\trl\\trainer\\sft_trainer.py:280: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ghosh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\trl\\trainer\\sft_trainer.py:318: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbe1e17293c74a2da743f234d8a7233c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/13500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecec852862d24193b0f88f1e2af89c58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ghosh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\trl\\trainer\\sft_trainer.py:408: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ghosh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\accelerate\\accelerator.py:488: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n",
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer ready!\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=16,\n",
    "    warmup_steps=50,\n",
    "    max_steps=800,\n",
    "    learning_rate=2e-4,\n",
    "    fp16=True,\n",
    "    logging_steps=10,\n",
    "    save_steps=200,\n",
    "    save_total_limit=2,\n",
    "    optim=\"paged_adamw_8bit\",\n",
    "    report_to=[],\n",
    "    disable_tqdm=False\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"test\"],\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=512,\n",
    "    peft_config=peft_config,\n",
    "    args=training_args,\n",
    ")\n",
    "\n",
    "print(\"Trainer ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1740df6",
   "metadata": {},
   "source": [
    "# START TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "461a5c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy allowlisted\n",
      "RNG loader patched (compatible with PyTorch 2.0+)\n",
      "Resuming from: C:\\Users\\ghosh\\Desktop\\Predictive-Transaction-intelligence-for-bfsi\\models\\phi3-fraud-detector\\checkpoint-400 (step 400)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ghosh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': dataset_text_field, max_seq_length. Will not be supported from version '1.0.0'.\n",
      "\n",
      "Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "c:\\Users\\ghosh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\trl\\trainer\\sft_trainer.py:280: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ghosh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\trl\\trainer\\sft_trainer.py:318: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ghosh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\trl\\trainer\\sft_trainer.py:408: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ghosh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\accelerate\\accelerator.py:488: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n",
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3eff31a0f15a49c1b381ffa79d5e935d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNG states restored (CPU + GPU)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ghosh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:838: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "You are not running the flash-attention implementation, expect numerical differences.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# === CELL: RESUME WITH COMPATIBLE RNG LOADER (PYTORCH 2.0+ FIX) ===\n",
    "from trl import SFTTrainer\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "from torch.serialization import add_safe_globals\n",
    "from transformers import Trainer\n",
    "\n",
    "# === 1. ALLOW NUMPY (AS BEFORE) ===\n",
    "add_safe_globals([np.core.multiarray._reconstruct])\n",
    "add_safe_globals([np.ndarray])\n",
    "add_safe_globals([np.dtype])\n",
    "for name in dir(np):\n",
    "    obj = getattr(np, name)\n",
    "    if isinstance(obj, type) and issubclass(obj, np.generic):\n",
    "        add_safe_globals([obj])\n",
    "\n",
    "print(\"NumPy allowlisted\")\n",
    "\n",
    "# === 2. COMPATIBLE RNG PATCH (WORKS WITH PYTORCH 2.0–2.6+) ===\n",
    "def compatible_load_rng_state(self, checkpoint):\n",
    "    \"\"\"Patched RNG loader for PyTorch compatibility\"\"\"\n",
    "    rng_file = os.path.join(checkpoint, \"rng_state.pth\")\n",
    "    if os.path.isfile(rng_file):\n",
    "        checkpoint_rng_state = torch.load(rng_file, weights_only=False)  # Safe for your checkpoint\n",
    "        \n",
    "        # Python RNG\n",
    "        random.setstate(checkpoint_rng_state[\"python\"])\n",
    "        \n",
    "        # NumPy RNG\n",
    "        np.random.set_state(checkpoint_rng_state[\"numpy\"])\n",
    "        \n",
    "        # Torch CPU RNG (standard method)\n",
    "        if \"torch\" in checkpoint_rng_state:\n",
    "            torch.set_rng_state(checkpoint_rng_state[\"torch\"])\n",
    "        \n",
    "        # Torch CUDA RNG (standard method)\n",
    "        if \"torch_cuda\" in checkpoint_rng_state:\n",
    "            torch.cuda.set_rng_state(checkpoint_rng_state[\"torch_cuda\"])\n",
    "        \n",
    "        # For multi-device (if PyTorch 2.1+ and function exists)\n",
    "        if hasattr(torch, 'set_rng_state_all') and \"torch\" in checkpoint_rng_state:\n",
    "            try:\n",
    "                torch.set_rng_state_all(checkpoint_rng_state[\"torch\"])\n",
    "            except:\n",
    "                pass  # Fallback to standard above\n",
    "        \n",
    "        print(\"RNG states restored (CPU + GPU)\")\n",
    "    else:\n",
    "        print(\"No RNG file found — continuing without RNG restore\")\n",
    "\n",
    "# Apply patch\n",
    "Trainer._load_rng_state = compatible_load_rng_state\n",
    "\n",
    "print(\"RNG loader patched (compatible with PyTorch 2.0+)\")\n",
    "\n",
    "# === 3. CHECKPOINT ===\n",
    "OUTPUT_DIR = r\"C:\\Users\\ghosh\\Desktop\\Predictive-Transaction-intelligence-for-bfsi\\models\\phi3-fraud-detector\"\n",
    "checkpoints = [d for d in os.listdir(OUTPUT_DIR) if d.startswith(\"checkpoint-\")]\n",
    "latest_checkpoint = sorted(checkpoints, key=lambda x: int(x.split('-')[-1]))[-1]\n",
    "resume_from = os.path.join(OUTPUT_DIR, latest_checkpoint)\n",
    "\n",
    "print(f\"Resuming from: {resume_from} (step {latest_checkpoint.split('-')[-1]})\")\n",
    "\n",
    "# === 4. RECREATE SFTTrainer (IGNORE DEPRECATION WARNINGS — THEY'RE HARMLESS) ===\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=512,\n",
    "    peft_config=peft_config,\n",
    ")\n",
    "\n",
    "# Fix padding_side warning (harmless but fixes overflow)\n",
    "tokenizer.padding_side = \"right\"\n",
    "\n",
    "# === 5. RESUME ===\n",
    "trainer.train(resume_from_checkpoint=resume_from)\n",
    "\n",
    "print(f\"Training resumed from step {trainer.state.global_step}\")\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe48b10",
   "metadata": {},
   "source": [
    "# Merge & Save Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5af717e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import AutoPeftModelForCausalLM\n",
    "\n",
    "merged_model = AutoPeftModelForCausalLM.from_pretrained(\n",
    "    os.path.join(OUTPUT_DIR, \"final\"),\n",
    "    device_map=\"cpu\",\n",
    "    torch_dtype=torch.float16\n",
    ")\n",
    "merged_model = merged_model.merge_and_unload()\n",
    "\n",
    "final_path = os.path.join(PROJECT_DIR, \"models\", \"phi3-fraud-merged\")\n",
    "merged_model.save_pretrained(final_path)\n",
    "tokenizer.save_pretrained(final_path)\n",
    "\n",
    "print(f\"Final merged model saved to {final_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e7a4e9",
   "metadata": {},
   "source": [
    "# Test Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd2ab45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=final_path,\n",
    "    tokenizer=final_path,\n",
    "    max_new_tokens=120,\n",
    "    temperature=0.3,\n",
    "    device=0  # GPU\n",
    ")\n",
    "\n",
    "prompt = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a fraud detection expert.\"},\n",
    "    {\"role\": \"user\", \"content\": \"User: 35yo male, USA. Avg spend: $120. Transaction: $980 on Electronics at 2:45 AM. IP in Nigeria. Fraud?\"}\n",
    "]\n",
    "\n",
    "input_text = tokenizer.apply_chat_template(prompt, tokenize=False, add_generation_prompt=True)\n",
    "output = pipe(input_text)[0][\"generated_text\"]\n",
    "print(output.split(\"assistant\")[-1].strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7372b7d",
   "metadata": {},
   "source": [
    "# Export to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2dca52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === FINAL CELL: EXPORT TO ONNX → api/ DIRECTORY ===\n",
    "import os, torch, subprocess, shutil\n",
    "from transformers import AutoTokenizer\n",
    "from peft import AutoPeftModelForCausalLM\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Paths\n",
    "PROJECT_DIR = r\"C:\\Users\\ghosh\\Desktop\\Predictive-Transaction-intelligence-for-bfsi\"\n",
    "LORA_DIR    = os.path.join(PROJECT_DIR, \"models\", \"phi3-fraud-detector\", \"final\")\n",
    "API_DIR     = os.path.join(PROJECT_DIR, \"api\")\n",
    "ONNX_DIR    = os.path.join(API_DIR, \"onnx_model\")\n",
    "os.makedirs(ONNX_DIR, exist_ok=True)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 1. Load & merge LoRA model\n",
    "print(\"Loading and merging LoRA model...\")\n",
    "model = AutoPeftModelForCausalLM.from_pretrained(\n",
    "    LORA_DIR, device_map=\"cpu\", torch_dtype=torch.float16\n",
    ")\n",
    "merged = model.merge_and_unload()\n",
    "tokenizer = AutoTokenizer.from_pretrained(LORA_DIR, trust_remote_code=True)\n",
    "\n",
    "# Save merged model temporarily (required for ONNX export)\n",
    "TEMP_DIR = os.path.join(PROJECT_DIR, \"temp_phi3_merged\")\n",
    "merged.save_pretrained(TEMP_DIR)\n",
    "tokenizer.save_pretrained(TEMP_DIR)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 2. Export to ONNX\n",
    "print(\"Exporting to ONNX...\")\n",
    "onnx_path = os.path.join(ONNX_DIR, \"phi3_fraud_detector.onnx\")\n",
    "cmd = [\n",
    "    \"python\", \"-m\", \"transformers.onnx\",\n",
    "    \"--model\", TEMP_DIR,\n",
    "    \"--feature=causal-lm\",\n",
    "    \"--atol=1e-3\",\n",
    "    ONNX_DIR\n",
    "]\n",
    "result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "\n",
    "if result.returncode == 0:\n",
    "    print(\"ONNX export successful!\")\n",
    "else:\n",
    "    raise RuntimeError(f\"ONNX export failed:\\n{result.stderr}\")\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 3. Copy tokenizer files\n",
    "for fname in [\"tokenizer.json\", \"tokenizer_config.json\", \"special_tokens_map.json\"]:\n",
    "    src = os.path.join(TEMP_DIR, fname)\n",
    "    dst = os.path.join(ONNX_DIR, fname)\n",
    "    if os.path.exists(src):\n",
    "        shutil.copy(src, dst)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 4. Create onnx_predict.py helper\n",
    "helper_code = '''import onnxruntime as ort\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer\n",
    "import os\n",
    "\n",
    "class Phi3ONNXFraudDetector:\n",
    "    def __init__(self, model_dir):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_dir, trust_remote_code=True)\n",
    "        model_path = os.path.join(model_dir, \"phi3_fraud_detector.onnx\")\n",
    "        self.session = ort.InferenceSession(\n",
    "            model_path,\n",
    "            providers=['CUDAExecutionProvider', 'CPUExecutionProvider']\n",
    "        )\n",
    "    \n",
    "    def predict(self, prompt: str, max_length: int = 128):\n",
    "        inputs = self.tokenizer(prompt, return_tensors=\"np\")\n",
    "        input_ids = inputs[\"input_ids\"].astype(np.int64)\n",
    "        generated = input_ids.copy()\n",
    "        for _ in range(max_length):\n",
    "            outputs = self.session.run(None, {\"input_ids\": generated})\n",
    "            next_token = np.argmax(outputs[0][:, -1, :], axis=-1, keepdims=True)\n",
    "            generated = np.concatenate([generated, next_token], axis=1)\n",
    "            if next_token.item() == self.tokenizer.eos_token_id:\n",
    "                break\n",
    "        return self.tokenizer.decode(generated[0], skip_special_tokens=True)\n",
    "'''\n",
    "\n",
    "helper_path = os.path.join(API_DIR, \"onnx_predict.py\")\n",
    "with open(helper_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(helper_code)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 5. Cleanup\n",
    "shutil.rmtree(TEMP_DIR, ignore_errors=True)\n",
    "\n",
    "print(\"\\nONNX EXPORT COMPLETE!\")\n",
    "print(f\"ONNX model   : {onnx_path}\")\n",
    "print(f\"Helper script: {helper_path}\")\n",
    "print(\"Use in FastAPI: from onnx_predict import Phi3ONNXFraudDetector\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
